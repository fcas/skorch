{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22d246ff",
   "metadata": {},
   "source": [
    "# Using Large Language Models as text classifiers with an sklearn interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74501674",
   "metadata": {},
   "source": [
    "In this notebook, we will learn how to use skorch's `ZeroShotClassifier` and `FewShotClassifier` to perform classification without any training thanks to the power of (Large) Language Models (LLMs). For this, we rely on the the [Hugging Face transformers](https://huggingface.co/docs/transformers/index) library, which allows us to use all the available text generation models provided by Hugging Face."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595cf8f6",
   "metadata": {},
   "source": [
    "<table align=\"left\"><td>\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/skorch-dev/skorch/blob/master/notebooks/LLM_Classifier.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>  \n",
    "</td><td>\n",
    "<a target=\"_blank\" href=\"https://github.com/skorch-dev/skorch/blob/master/notebooks/LLM_Classifier.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a></td></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14fd81e",
   "metadata": {},
   "source": [
    "The notebook requires Hugging Face `transformers` and `datasets` as additional dependencies. If you have not already installed it, you can do so like this:\n",
    "\n",
    "`python -m pip install transformers datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e06744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Installation on Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    subprocess.run(['python', '-m', 'pip', 'install', 'skorch', 'transformers', 'datasets'])\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18a9e70",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fb9b863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "170f07d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's reduce some of the noise from transformers and datasets logs\n",
    "transformers.logging.set_verbosity_warning()\n",
    "datasets.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3a748a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b17651",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765481ec",
   "metadata": {},
   "source": [
    "For this example, we make use of the IMDB dataset. It consists of movie reviews written by IMDB users and the target is the sentiment, i.e. \"positive\" or \"negative\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e7cbed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da2231492f14b47a8c0b21970e6c3f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imdb = datasets.load_dataset('imdb').shuffle(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14e4f75",
   "metadata": {},
   "source": [
    "We limit the number of samples to 100. Using zero/few-shot learning mostly makes sense when there are few labeled samples, otherwise, supervised machine learning methods will probably give better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1abbf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imdb['train'][:100]['text']\n",
    "y = imdb['train'][:100]['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a682af",
   "metadata": {},
   "source": [
    "Let's take a quick look at the data. Our `X` contains the user reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e8b7b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We always watch American movies with their particular accents from each region (south, west, etc). We have the same here. All foreign people must to watch this movie and need to have a open mind to accept another culture, besides American and European almost dominate the cinematographic industry.<br /><br />This movie tell us about a parallel world which it isn't figured even for those who live in a big city like São Paulo. All actors are improvising and they are very realistic. The camera give us an idea of their confuse world, the loneliness of each character and invite us to share their world.<br /><br />It's a real great movie and worst a rent even have it at home.\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faadcf34",
   "metadata": {},
   "source": [
    "Our `y` contains the label-encoded targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c580060a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3baf13",
   "metadata": {},
   "source": [
    "For a standard machine learning solution, having label-encoded targets is desired. Here, we prefer to have the actual labels, however. It is much easier for the language model to predict the label \"positive\" for the text above than to predict \"1\". How would it know what \"1\" means? Sure, if we provide a few examples, it may work, but let's not make the language model's life harder than necessary and thus provide the actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33c309be",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(['negative', 'positive'])[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f5623a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'positive', 'negative', 'positive', 'negative'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533516d0",
   "metadata": {},
   "source": [
    "## Zero-shot classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8501ee6",
   "metadata": {},
   "source": [
    "Now let's see how we can use zero-shot classification with skorch. First, let's load the `ZeroShotClassifier` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e437375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.llm import ZeroShotClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d24ab00",
   "metadata": {},
   "source": [
    "### \"train\" zero-shot classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458dd970",
   "metadata": {},
   "source": [
    "For demonstration purposes, we use a small language model here, `flan-t5-small`, which is hosted on Hugging Face. It has the advantage that it's quite fast and, as we'll see, still performs quite well. For more details on this model, check out [its model card on Hugging Face](https://huggingface.co/google/flan-t5-small)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a4a5f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ZeroShotClassifier('google/flan-t5-small', device=device, use_caching=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e93588",
   "metadata": {},
   "source": [
    "Notes: \n",
    "\n",
    "- `flan-t5` has an encoder-decoder architecture, for which caching is not available, which is why we turn it off. The loss of speed shouldn't matter much for this task.\n",
    "- At the moment, we only support Hugging Face transformers models, or models that are compatible with it. We don't support APIs, so using OpenAI is not possible. For this, take a look at [scikit-llm](https://github.com/iryna-kondr/scikit-llm), which works with OpenAI. There are some restrictions associated with using an API, though, which means that not all features are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12888d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.22 s, sys: 837 ms, total: 4.06 s\n",
      "Wall time: 5 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ZeroShotClassifier(device=&#x27;cuda:0&#x27;, model_name=&#x27;google/flan-t5-small&#x27;, use_caching=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ZeroShotClassifier</label><div class=\"sk-toggleable__content\"><pre>ZeroShotClassifier(device=&#x27;cuda:0&#x27;, model_name=&#x27;google/flan-t5-small&#x27;, use_caching=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ZeroShotClassifier(device='cuda:0', model_name='google/flan-t5-small', use_caching=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X=None, y=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a7ba7b",
   "metadata": {},
   "source": [
    "In general, fitting is fast because, basically, nothing happens. If the transformers model and tokenizer are not cached locally, they will, however, be downloaded from Hugging Face, which may take some time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6143c8fb",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e6df68",
   "metadata": {},
   "source": [
    "Let's evaluate how well the model works. As with any sklearn-compatible model, we can just call `predict_proba` to get the probabilities that the model assigns to each sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a17bf2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (844 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.3 s, sys: 1.41 s, total: 30.7 s\n",
      "Wall time: 8.15 s\n"
     ]
    }
   ],
   "source": [
    "%time y_proba = clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f31ed19",
   "metadata": {},
   "source": [
    "The prediction speed is a bit slow, as should be expected from a language model. If runtime is a big concern, this is probably not the right approach.\n",
    "\n",
    "Now let's check how well the model does. First we check the log loss, then the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fc5b571",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2870120002577984"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d981cc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_proba.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0d4b490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14179b24",
   "metadata": {},
   "source": [
    "Given that this is zero-shot, those scores are actually not so bad!\n",
    "\n",
    "Sure, on the [leaderboard](https://huggingface.co/spaces/autoevaluate/leaderboards?dataset=imdb&only_verified=0&task=-any-&config=-unspecified-&split=-unspecified-&metric=accuracy) we can find models with better accuracy, but those are fine-tuned on the dataset.\n",
    "\n",
    "Notice that if we call `predict`, we get back the labels, i.e. \"positive\" or \"negative\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6807dc86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive'], dtype='<U8')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([\"A masterpiece, instant classic, 5 stars out of 5\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514abfc2",
   "metadata": {},
   "source": [
    "### Grid searching the prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385d445d",
   "metadata": {},
   "source": [
    "Since `ZeroShotClassifier` is sckit-learn compatible, we can easily do a grid search for the best prompt. In this example, let's compare two different prompts that are worded slightly differently. Could one of them be the better choice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c77f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt0 = \"\"\"You are a text classification assistant.\n",
    "\n",
    "The text to classify:\n",
    "\n",
    "```\n",
    "{text}\n",
    "```\n",
    "\n",
    "Choose the label among the following possibilities with the highest probability.\n",
    "Only return the label, nothing more:\n",
    "\n",
    "{labels}\n",
    "\n",
    "Your response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3843a146",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = \"\"\"Your task is to classify text.\n",
    "\n",
    "Choose the label among the following possibilities with the highest probability.\n",
    "Only return the label, nothing more:\n",
    "\n",
    "{labels}\n",
    "\n",
    "The text to classify:\n",
    "\n",
    "```\n",
    "{text}\n",
    "```\n",
    "\n",
    "Your response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b403856",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'prompt': [prompt0, prompt1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfa08d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(clf, param_grid=params, cv=2, scoring=['accuracy', 'neg_log_loss'], refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38d17dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (844 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (885 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (844 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (885 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 2s, sys: 6.01 s, total: 2min 8s\n",
      "Wall time: 36 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=ZeroShotClassifier(device=&#x27;cuda:0&#x27;, model_name=&#x27;google/flan-t5-small&#x27;, use_caching=False),\n",
       "             param_grid={&#x27;prompt&#x27;: [&#x27;You are a text classification assistant.\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;The text to classify:\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;```\\n&#x27;\n",
       "                                    &#x27;{text}\\n&#x27;\n",
       "                                    &#x27;```\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;Choose the label among the following &#x27;\n",
       "                                    &#x27;possibilities with the highest &#x27;\n",
       "                                    &#x27;probability.\\n&#x27;\n",
       "                                    &#x27;Only return the label, nothing more:\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;{labels}\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;Your response:\\n&#x27;,\n",
       "                                    &#x27;Your task is to classify text.\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;Choose the label among the following &#x27;\n",
       "                                    &#x27;possibilities with the highest &#x27;\n",
       "                                    &#x27;probability.\\n&#x27;\n",
       "                                    &#x27;Only return the label, nothing more:\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;{labels}\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;The text to classify:\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;```\\n&#x27;\n",
       "                                    &#x27;{text}\\n&#x27;\n",
       "                                    &#x27;```\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;Your response:\\n&#x27;]},\n",
       "             refit=False, scoring=[&#x27;accuracy&#x27;, &#x27;neg_log_loss&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=ZeroShotClassifier(device=&#x27;cuda:0&#x27;, model_name=&#x27;google/flan-t5-small&#x27;, use_caching=False),\n",
       "             param_grid={&#x27;prompt&#x27;: [&#x27;You are a text classification assistant.\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;The text to classify:\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;```\\n&#x27;\n",
       "                                    &#x27;{text}\\n&#x27;\n",
       "                                    &#x27;```\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;Choose the label among the following &#x27;\n",
       "                                    &#x27;possibilities with the highest &#x27;\n",
       "                                    &#x27;probability.\\n&#x27;\n",
       "                                    &#x27;Only return the label, nothing more:\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;{labels}\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;Your response:\\n&#x27;,\n",
       "                                    &#x27;Your task is to classify text.\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;Choose the label among the following &#x27;\n",
       "                                    &#x27;possibilities with the highest &#x27;\n",
       "                                    &#x27;probability.\\n&#x27;\n",
       "                                    &#x27;Only return the label, nothing more:\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;{labels}\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;The text to classify:\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;```\\n&#x27;\n",
       "                                    &#x27;{text}\\n&#x27;\n",
       "                                    &#x27;```\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;Your response:\\n&#x27;]},\n",
       "             refit=False, scoring=[&#x27;accuracy&#x27;, &#x27;neg_log_loss&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ZeroShotClassifier</label><div class=\"sk-toggleable__content\"><pre>ZeroShotClassifier(device=&#x27;cuda:0&#x27;, model_name=&#x27;google/flan-t5-small&#x27;, use_caching=False)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ZeroShotClassifier</label><div class=\"sk-toggleable__content\"><pre>ZeroShotClassifier(device=&#x27;cuda:0&#x27;, model_name=&#x27;google/flan-t5-small&#x27;, use_caching=False)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=ZeroShotClassifier(device='cuda:0', model_name='google/flan-t5-small', use_caching=False),\n",
       "             param_grid={'prompt': ['You are a text classification assistant.\\n'\n",
       "                                    '\\n'\n",
       "                                    'The text to classify:\\n'\n",
       "                                    '\\n'\n",
       "                                    '```\\n'\n",
       "                                    '{text}\\n'\n",
       "                                    '```\\n'\n",
       "                                    '\\n'\n",
       "                                    'Choose the label among the following '\n",
       "                                    'possibilities with the highest '\n",
       "                                    'probability.\\n'\n",
       "                                    'Only return the label, nothing more:\\n'\n",
       "                                    '\\n'\n",
       "                                    '{labels}\\n'\n",
       "                                    '\\n'\n",
       "                                    'Your response:\\n',\n",
       "                                    'Your task is to classify text.\\n'\n",
       "                                    '\\n'\n",
       "                                    'Choose the label among the following '\n",
       "                                    'possibilities with the highest '\n",
       "                                    'probability.\\n'\n",
       "                                    'Only return the label, nothing more:\\n'\n",
       "                                    '\\n'\n",
       "                                    '{labels}\\n'\n",
       "                                    '\\n'\n",
       "                                    'The text to classify:\\n'\n",
       "                                    '\\n'\n",
       "                                    '```\\n'\n",
       "                                    '{text}\\n'\n",
       "                                    '```\\n'\n",
       "                                    '\\n'\n",
       "                                    'Your response:\\n']},\n",
       "             refit=False, scoring=['accuracy', 'neg_log_loss'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time search.fit(X, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965c3bf1",
   "metadata": {},
   "source": [
    "grid search results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92132751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>param_prompt</th>\n",
       "      <th>mean_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.86</td>\n",
       "      <td>-0.287012</td>\n",
       "      <td>You are a text classification assistant.\\n\\nTh...</td>\n",
       "      <td>7.623799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.93</td>\n",
       "      <td>-0.246949</td>\n",
       "      <td>Your task is to classify text.\\n\\nChoose the l...</td>\n",
       "      <td>7.354391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_accuracy  mean_test_neg_log_loss  \\\n",
       "0                0.86               -0.287012   \n",
       "1                0.93               -0.246949   \n",
       "\n",
       "                                        param_prompt  mean_score_time  \n",
       "0  You are a text classification assistant.\\n\\nTh...         7.623799  \n",
       "1  Your task is to classify text.\\n\\nChoose the l...         7.354391  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(search.cv_results_)[['mean_test_accuracy', 'mean_test_neg_log_loss', 'param_prompt', 'mean_score_time']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac85f73",
   "metadata": {},
   "source": [
    "**Conclusion**: `prompt1` is performing better than `prompt0`. The mean test accuracy of 93% and log loss of 0.25 are pretty good overall, given that we use zero-shot and don't perform any fine-tuning.\n",
    "\n",
    "Going further, we could also grid search different language models, or combinations of LLMs and prompts, to find the best working zero-shot model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5102989",
   "metadata": {},
   "source": [
    "## Few-shot classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d6f4f4",
   "metadata": {},
   "source": [
    "Sometimes, helping the language model out by providing a few examples will boost the performance. To test this, we skorch provides the `FewShotClassifier` class. Let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a6faa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.llm import FewShotClassifier\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9c34f3",
   "metadata": {},
   "source": [
    "### train the few-shot classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e9b863",
   "metadata": {},
   "source": [
    "Instead of passing the model name to initialize the classifier, as in `clf = FewShotClassifier('google/flan-t5-small')`, it is also possible to pass the model and tokenizer explicitly. This is a good option if you need more control over them. In our case, it amounts to the same result. It's useful to keep this option in mind, though, if the model requires any changes or if you want to provide a model that is not uploaded to Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d385ea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-small').to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-small')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6995d4",
   "metadata": {},
   "source": [
    "To control the amount of samples used for few-shot learning, use `max_samples` parameter. In this case, let's use 5 examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61b63a7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = FewShotClassifier(\n",
    "    model=model, tokenizer=tokenizer, max_samples=5, use_caching=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8803fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 1.66 ms, total: 1.66 ms\n",
      "Wall time: 847 µs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>FewShotClassifier(model=&#x27;T5ForConditionalGeneration&#x27;, tokenizer=&#x27;T5TokenizerFast&#x27;, use_caching=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FewShotClassifier</label><div class=\"sk-toggleable__content\"><pre>FewShotClassifier(model=&#x27;T5ForConditionalGeneration&#x27;, tokenizer=&#x27;T5TokenizerFast&#x27;, use_caching=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "FewShotClassifier(model='T5ForConditionalGeneration', tokenizer='T5TokenizerFast', use_caching=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfe57f9",
   "metadata": {},
   "source": [
    "Let's make sure that everything works as expected by inspecting the prompt. This is possible using the `get_prompt` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a368d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a text classification assistant.\n",
      "\n",
      "Choose the label among the following possibilities with the highest probability.\n",
      "Only return the label, nothing more:\n",
      "\n",
      "['negative', 'positive']\n",
      "\n",
      "Here are a few examples:\n",
      "\n",
      "```\n",
      "You know, this movie isn't that great, but, I mean, c'mon, it's about angels helping a baseball team. I find the plot line to be hilarious anyways, this kid's dad says he'll take him back if the angels win the pennant (because he knows they won't) Kid prays to his fake god to help the angels win, god helps the whole time (via the angel Christopher Lloyd, RIP) And in the end, his dad doesn't take him back and rides off on his motorcycle right in that kids face. it's hilarious until Danny Glover adopts it and it's friend.<br /><br />I guess the upside is that the old lady is left alone to die with her stitchin' projects and her stories. The real winner here, though, is god. Because later he got a job as a writer for numerous prank shows.<br /><br />As a kids movie, it gets a 7. As a movie about the mysteries of blind, stupid faith, and the nature of \"god,\" it gets a 10.\n",
      "```\n",
      "\n",
      "Your response:\n",
      "positive\n",
      "\n",
      "```\n",
      "This is one of the best made movies from 2002. Maybe it is not the best movie, but it looks the best, has great acting and is directed perfectly by Sam Mendes, who debuted with 'American Beauty'.<br /><br />It tells the story of a gangster named Michael Sullivan (Tom Hanks) who is seen by his son (Tyler Hoechlin) on one of his jobs. Michael's boss, John Rooney (Paul Newman), thinks things will be okay but his jealous son Connor Rooney (Daniel Craig) sets both his father and Michael up, leading to the death of Michael's wife (Jennifer Jason Leigh) and second son. Michael thinks Rooney is responsible and Rooney has to choose for himself and sends a hit-man Harlen Maguire (Jude Law) to finish the job. Since Michael is a respected man within the organization he tries to win some friends who can help him including mob boss Frank Nitti (Stanley Tucci).<br /><br />In a way 'Road to Perdition' is a standard gangster movie but it is so well made you almost can not see that. This movie is good in its production design, art direction, sound, music and most of all in its cinematography. All these elements are able to surprise and create suspense although the outcome is pretty certain. That Hoechlin is not a annoying kid and Hanks, Law and Newman know how to act helps, of course.<br /><br />Based on a comic this movie is so much better than you would expect and although it has it flaws it belongs to the better movies in the genre. Sometimes there are events where you realize you have seen it so many times before, but for some reason it also feels fresh at the same time. The scenes between the adult Hanks and the child Hoechlin help in that area. See this movie that will look familiar at times but is totally new on a lot of areas.\n",
      "```\n",
      "\n",
      "Your response:\n",
      "positive\n",
      "\n",
      "```\n",
      "I'll give this movie two stars because it teems with beautiful photography. Otherwise, it teems mainly with clichés and stereotypes: mountain people are either dumb white trash of the fanatically religious or ragged racist kind, or wise white Indians. Indians are magical people who move around without a sound, can disappear in the blink of an eye, talk to animals, and read minds over large distances. And so on and so forth.<br /><br />Throughout the movie I kept wondering what the point of the film was (other than showing me pretty pictures of mountains, log cabins, woods, an assortment of animals, free-spirited mountain-dwellers and freaky people in church).<br /><br />The plot touched a whole range of issues but explored none of them in depth. This was neither a story about growing up during the depression, nor about about being an orphan, nor about a struggle for identity. It tried to be all of those things and more, which made it superficial and unsatisfactory.<br /><br />Although the movie was supposed to be about Little Tree's education, we learn almost nothing about it. He was given a brief summary of the history of his people (who were brave and stoic) and a distillery demonstration; tried his hand at chopping wood (at which he failed) and whiskey running (literally); learned how to read (and maybe to write) with the help of grandma and her dictionary - and that was it. Apparently he didn't learn much during his stint in boarding school because he was locked up in the attic.<br /><br />However, grandma and grandpa and Graham Greene's character made sure that in the end Little Tree became a very spiritual person whose main goal as an adult - after, and I'm paraphrasing here, \"riding with the Navajos\" and \"getting caught up in a couple of wars\" - was to \"catch up\" with grandma and grandpa and Graham Greene's character in heaven (instead of, say, dating girls, getting married, having children or other such nonsense).<br /><br />Last but not least I must say that I found grandpa's trade offensive. Why of all things did it have to be a whiskey still? To counteract the stereotype of the \"drunken Indian\"?\n",
      "```\n",
      "\n",
      "Your response:\n",
      "negative\n",
      "\n",
      "```\n",
      "I'll give this movie two stars because it teems with beautiful photography. Otherwise, it teems mainly with clichés and stereotypes: mountain people are either dumb white trash of the fanatically religious or ragged racist kind, or wise white Indians. Indians are magical people who move around without a sound, can disappear in the blink of an eye, talk to animals, and read minds over large distances. And so on and so forth.<br /><br />Throughout the movie I kept wondering what the point of the film was (other than showing me pretty pictures of mountains, log cabins, woods, an assortment of animals, free-spirited mountain-dwellers and freaky people in church).<br /><br />The plot touched a whole range of issues but explored none of them in depth. This was neither a story about growing up during the depression, nor about about being an orphan, nor about a struggle for identity. It tried to be all of those things and more, which made it superficial and unsatisfactory.<br /><br />Although the movie was supposed to be about Little Tree's education, we learn almost nothing about it. He was given a brief summary of the history of his people (who were brave and stoic) and a distillery demonstration; tried his hand at chopping wood (at which he failed) and whiskey running (literally); learned how to read (and maybe to write) with the help of grandma and her dictionary - and that was it. Apparently he didn't learn much during his stint in boarding school because he was locked up in the attic.<br /><br />However, grandma and grandpa and Graham Greene's character made sure that in the end Little Tree became a very spiritual person whose main goal as an adult - after, and I'm paraphrasing here, \"riding with the Navajos\" and \"getting caught up in a couple of wars\" - was to \"catch up\" with grandma and grandpa and Graham Greene's character in heaven (instead of, say, dating girls, getting married, having children or other such nonsense).<br /><br />Last but not least I must say that I found grandpa's trade offensive. Why of all things did it have to be a whiskey still? To counteract the stereotype of the \"drunken Indian\"?\n",
      "```\n",
      "\n",
      "Your response:\n",
      "negative\n",
      "\n",
      "```\n",
      "I've just finished viewing the 1st disc in a 4-disc (26 episodes) collection created in conjunction with the UCLA Film & Television Archive (S'More Entertainment, Inc.). So far (aside from the 1st episode), the image quality is quite good. The DVD box is shown on the title page here on IMDb.<br /><br />\"Mr. Peepers\" is just as charming as when I first saw it (5-years old at the time) and Wally Cox is truly endearing in this role. If you're in the mood for quiet comedy that sneaks up on you, as opposed to hitting you over the head, you'll treasure this chance to experience all the wonderful characters you might remember from your childhood. Although some of the gags are a bit corny, most are ingenious and well-executed...and even the corny ones are fun. This is one TV series that lives up to my early childhood memories of it.\n",
      "```\n",
      "\n",
      "Your response:\n",
      "positive\n",
      "\n",
      "\n",
      "The text to classify:\n",
      "\n",
      "```\n",
      "A masterpiece, instant classic, 5 stars out of 5\n",
      "```\n",
      "\n",
      "Your response:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(clf.get_prompt(\"A masterpiece, instant classic, 5 stars out of 5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eb015f",
   "metadata": {},
   "source": [
    "If we're unhappy with the prompt, we can also provide our own prompt using the `prompt` argument, as we saw earlier in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8477a3a",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45e77c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2414 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 41s, sys: 4.48 s, total: 1min 46s\n",
      "Wall time: 26.8 s\n"
     ]
    }
   ],
   "source": [
    "%time y_proba = clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f53a4fda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23183602008608978"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "844d95d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_proba.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf46193d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "686347e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative'], dtype='<U8')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([\"Even if paid $1000, I would not watch this movie again\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c681fbd",
   "metadata": {},
   "source": [
    "This looks like a small improvement over what we got with zero-shot learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45051abb",
   "metadata": {},
   "source": [
    "### grid search best number of few-shot samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9a1ed5",
   "metadata": {},
   "source": [
    "Maybe we can do even better if we pick a better number of samples for few-shot learning? Let's try this out with grid search.\n",
    "\n",
    "Note that grid search will split `X` and `y` for each run. Since the few-shot samples are taken from `X` and `y`, those will thus be different for each split, which could have a big influence on the performance of the model. If you always want to have the same few-shot samples in each split, you should craft your own prompt with those examples and then use it with `ZeroShotClassifier`. Just ensure that those prompts are not part of the validation/test data!\n",
    "\n",
    "Now let's test 3, 5, and 7 samples and see what works best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b228cacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_samples': [3, 5, 7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99465fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(clf, param_grid=params, cv=2, scoring=['accuracy', 'neg_log_loss'], refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65281e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 37s, sys: 19.7 s, total: 7min 57s\n",
      "Wall time: 2min 19s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=FewShotClassifier(model=T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_...\n",
       "), tokenizer=T5TokenizerFast(name_or_path=&#x27;google/flan-t5-small&#x27;, vocab_size=32100, model_max_length=512, is_fast=True, padding_side=&#x27;right&#x27;, truncation_side=&#x27;right&#x27;, special_tokens={&#x27;eos_token&#x27;: &#x27;&lt;/s&gt;&#x27;, &#x27;unk_token&#x27;: &#x27;&lt;unk&gt;&#x27;, &#x27;pad_token&#x27;: &#x27;&lt;pad&gt;&#x27;, &#x27;additional_special_tokens&#x27;: [&#x27;&lt;extra_id_0&gt;&#x27;, &#x27;&lt;extra_id_1&gt;&#x27;, &#x27;&lt;extra_id_2&gt;&#x27;, &#x27;&lt;extra_id_3&gt;&#x27;, &#x27;&lt;extra_id_4&gt;&#x27;, &#x27;&lt;extra_id_5&gt;&#x27;, &#x27;&lt;extra_id_6&gt;&#x27;, &#x27;&lt;extra_id_7&gt;&#x27;, &#x27;&lt;extra_id_8&gt;&#x27;, &#x27;&lt;extra_id_9&gt;&#x27;, &#x27;&lt;extra_id_10&gt;&#x27;, &#x27;&lt;extra_id_11&gt;&#x27;, &#x27;&lt;extra_id_12&gt;&#x27;, &#x27;&lt;extra_id_13&gt;&#x27;, &#x27;&lt;extra_id_14&gt;&#x27;, &#x27;&lt;extra_id_15&gt;&#x27;, &#x27;&lt;extra_id_16&gt;&#x27;, &#x27;&lt;extra_id_17&gt;&#x27;, &#x27;&lt;extra_id_18&gt;&#x27;, &#x27;&lt;extra_id_19&gt;&#x27;, &#x27;&lt;extra_id_20&gt;&#x27;, &#x27;&lt;extra_id_21&gt;&#x27;, &#x27;&lt;extra_id_22&gt;&#x27;, &#x27;&lt;extra_id_23&gt;&#x27;, &#x27;&lt;extra_id_24&gt;&#x27;, &#x27;&lt;extra_id_25&gt;&#x27;, &#x27;&lt;extra_id_26&gt;&#x27;, &#x27;&lt;extra_id_27&gt;&#x27;, &#x27;&lt;extra_id_28&gt;&#x27;, &#x27;&lt;extra_id_29&gt;&#x27;, &#x27;&lt;extra_id_30&gt;&#x27;, &#x27;&lt;extra_id_31&gt;&#x27;, &#x27;&lt;extra_id_32&gt;&#x27;, &#x27;&lt;extra_id_33&gt;&#x27;, &#x27;&lt;extra_id_34&gt;&#x27;, &#x27;&lt;extra_id_35&gt;&#x27;, &#x27;&lt;extra_id_36&gt;&#x27;, &#x27;&lt;extra_id_37&gt;&#x27;, &#x27;&lt;extra_id_38&gt;&#x27;, &#x27;&lt;extra_id_39&gt;&#x27;, &#x27;&lt;extra_id_40&gt;&#x27;, &#x27;&lt;extra_id_41&gt;&#x27;, &#x27;&lt;extra_id_42&gt;&#x27;, &#x27;&lt;extra_id_43&gt;&#x27;, &#x27;&lt;extra_id_44&gt;&#x27;, &#x27;&lt;extra_id_45&gt;&#x27;, &#x27;&lt;extra_id_46&gt;&#x27;, &#x27;&lt;extra_id_47&gt;&#x27;, &#x27;&lt;extra_id_48&gt;&#x27;, &#x27;&lt;extra_id_49&gt;&#x27;, &#x27;&lt;extra_id_50&gt;&#x27;, &#x27;&lt;extra_id_51&gt;&#x27;, &#x27;&lt;extra_id_52&gt;&#x27;, &#x27;&lt;extra_id_53&gt;&#x27;, &#x27;&lt;extra_id_54&gt;&#x27;, &#x27;&lt;extra_id_55&gt;&#x27;, &#x27;&lt;extra_id_56&gt;&#x27;, &#x27;&lt;extra_id_57&gt;&#x27;, &#x27;&lt;extra_id_58&gt;&#x27;, &#x27;&lt;extra_id_59&gt;&#x27;, &#x27;&lt;extra_id_60&gt;&#x27;, &#x27;&lt;extra_id_61&gt;&#x27;, &#x27;&lt;extra_id_62&gt;&#x27;, &#x27;&lt;extra_id_63&gt;&#x27;, &#x27;&lt;extra_id_64&gt;&#x27;, &#x27;&lt;extra_id_65&gt;&#x27;, &#x27;&lt;extra_id_66&gt;&#x27;, &#x27;&lt;extra_id_67&gt;&#x27;, &#x27;&lt;extra_id_68&gt;&#x27;, &#x27;&lt;extra_id_69&gt;&#x27;, &#x27;&lt;extra_id_70&gt;&#x27;, &#x27;&lt;extra_id_71&gt;&#x27;, &#x27;&lt;extra_id_72&gt;&#x27;, &#x27;&lt;extra_id_73&gt;&#x27;, &#x27;&lt;extra_id_74&gt;&#x27;, &#x27;&lt;extra_id_75&gt;&#x27;, &#x27;&lt;extra_id_76&gt;&#x27;, &#x27;&lt;extra_id_77&gt;&#x27;, &#x27;&lt;extra_id_78&gt;&#x27;, &#x27;&lt;extra_id_79&gt;&#x27;, &#x27;&lt;extra_id_80&gt;&#x27;, &#x27;&lt;extra_id_81&gt;&#x27;, &#x27;&lt;extra_id_82&gt;&#x27;, &#x27;&lt;extra_id_83&gt;&#x27;, &#x27;&lt;extra_id_84&gt;&#x27;, &#x27;&lt;extra_id_85&gt;&#x27;, &#x27;&lt;extra_id_86&gt;&#x27;, &#x27;&lt;extra_id_87&gt;&#x27;, &#x27;&lt;extra_id_88&gt;&#x27;, &#x27;&lt;extra_id_89&gt;&#x27;, &#x27;&lt;extra_id_90&gt;&#x27;, &#x27;&lt;extra_id_91&gt;&#x27;, &#x27;&lt;extra_id_92&gt;&#x27;, &#x27;&lt;extra_id_93&gt;&#x27;, &#x27;&lt;extra_id_94&gt;&#x27;, &#x27;&lt;extra_id_95&gt;&#x27;, &#x27;&lt;extra_id_96&gt;&#x27;, &#x27;&lt;extra_id_97&gt;&#x27;, &#x27;&lt;extra_id_98&gt;&#x27;, &#x27;&lt;extra_id_99&gt;&#x27;]}, clean_up_tokenization_spaces=True), use_caching=False),\n",
       "             param_grid={&#x27;max_samples&#x27;: [3, 5, 7]}, refit=False,\n",
       "             scoring=[&#x27;accuracy&#x27;, &#x27;neg_log_loss&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=FewShotClassifier(model=T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_...\n",
       "), tokenizer=T5TokenizerFast(name_or_path=&#x27;google/flan-t5-small&#x27;, vocab_size=32100, model_max_length=512, is_fast=True, padding_side=&#x27;right&#x27;, truncation_side=&#x27;right&#x27;, special_tokens={&#x27;eos_token&#x27;: &#x27;&lt;/s&gt;&#x27;, &#x27;unk_token&#x27;: &#x27;&lt;unk&gt;&#x27;, &#x27;pad_token&#x27;: &#x27;&lt;pad&gt;&#x27;, &#x27;additional_special_tokens&#x27;: [&#x27;&lt;extra_id_0&gt;&#x27;, &#x27;&lt;extra_id_1&gt;&#x27;, &#x27;&lt;extra_id_2&gt;&#x27;, &#x27;&lt;extra_id_3&gt;&#x27;, &#x27;&lt;extra_id_4&gt;&#x27;, &#x27;&lt;extra_id_5&gt;&#x27;, &#x27;&lt;extra_id_6&gt;&#x27;, &#x27;&lt;extra_id_7&gt;&#x27;, &#x27;&lt;extra_id_8&gt;&#x27;, &#x27;&lt;extra_id_9&gt;&#x27;, &#x27;&lt;extra_id_10&gt;&#x27;, &#x27;&lt;extra_id_11&gt;&#x27;, &#x27;&lt;extra_id_12&gt;&#x27;, &#x27;&lt;extra_id_13&gt;&#x27;, &#x27;&lt;extra_id_14&gt;&#x27;, &#x27;&lt;extra_id_15&gt;&#x27;, &#x27;&lt;extra_id_16&gt;&#x27;, &#x27;&lt;extra_id_17&gt;&#x27;, &#x27;&lt;extra_id_18&gt;&#x27;, &#x27;&lt;extra_id_19&gt;&#x27;, &#x27;&lt;extra_id_20&gt;&#x27;, &#x27;&lt;extra_id_21&gt;&#x27;, &#x27;&lt;extra_id_22&gt;&#x27;, &#x27;&lt;extra_id_23&gt;&#x27;, &#x27;&lt;extra_id_24&gt;&#x27;, &#x27;&lt;extra_id_25&gt;&#x27;, &#x27;&lt;extra_id_26&gt;&#x27;, &#x27;&lt;extra_id_27&gt;&#x27;, &#x27;&lt;extra_id_28&gt;&#x27;, &#x27;&lt;extra_id_29&gt;&#x27;, &#x27;&lt;extra_id_30&gt;&#x27;, &#x27;&lt;extra_id_31&gt;&#x27;, &#x27;&lt;extra_id_32&gt;&#x27;, &#x27;&lt;extra_id_33&gt;&#x27;, &#x27;&lt;extra_id_34&gt;&#x27;, &#x27;&lt;extra_id_35&gt;&#x27;, &#x27;&lt;extra_id_36&gt;&#x27;, &#x27;&lt;extra_id_37&gt;&#x27;, &#x27;&lt;extra_id_38&gt;&#x27;, &#x27;&lt;extra_id_39&gt;&#x27;, &#x27;&lt;extra_id_40&gt;&#x27;, &#x27;&lt;extra_id_41&gt;&#x27;, &#x27;&lt;extra_id_42&gt;&#x27;, &#x27;&lt;extra_id_43&gt;&#x27;, &#x27;&lt;extra_id_44&gt;&#x27;, &#x27;&lt;extra_id_45&gt;&#x27;, &#x27;&lt;extra_id_46&gt;&#x27;, &#x27;&lt;extra_id_47&gt;&#x27;, &#x27;&lt;extra_id_48&gt;&#x27;, &#x27;&lt;extra_id_49&gt;&#x27;, &#x27;&lt;extra_id_50&gt;&#x27;, &#x27;&lt;extra_id_51&gt;&#x27;, &#x27;&lt;extra_id_52&gt;&#x27;, &#x27;&lt;extra_id_53&gt;&#x27;, &#x27;&lt;extra_id_54&gt;&#x27;, &#x27;&lt;extra_id_55&gt;&#x27;, &#x27;&lt;extra_id_56&gt;&#x27;, &#x27;&lt;extra_id_57&gt;&#x27;, &#x27;&lt;extra_id_58&gt;&#x27;, &#x27;&lt;extra_id_59&gt;&#x27;, &#x27;&lt;extra_id_60&gt;&#x27;, &#x27;&lt;extra_id_61&gt;&#x27;, &#x27;&lt;extra_id_62&gt;&#x27;, &#x27;&lt;extra_id_63&gt;&#x27;, &#x27;&lt;extra_id_64&gt;&#x27;, &#x27;&lt;extra_id_65&gt;&#x27;, &#x27;&lt;extra_id_66&gt;&#x27;, &#x27;&lt;extra_id_67&gt;&#x27;, &#x27;&lt;extra_id_68&gt;&#x27;, &#x27;&lt;extra_id_69&gt;&#x27;, &#x27;&lt;extra_id_70&gt;&#x27;, &#x27;&lt;extra_id_71&gt;&#x27;, &#x27;&lt;extra_id_72&gt;&#x27;, &#x27;&lt;extra_id_73&gt;&#x27;, &#x27;&lt;extra_id_74&gt;&#x27;, &#x27;&lt;extra_id_75&gt;&#x27;, &#x27;&lt;extra_id_76&gt;&#x27;, &#x27;&lt;extra_id_77&gt;&#x27;, &#x27;&lt;extra_id_78&gt;&#x27;, &#x27;&lt;extra_id_79&gt;&#x27;, &#x27;&lt;extra_id_80&gt;&#x27;, &#x27;&lt;extra_id_81&gt;&#x27;, &#x27;&lt;extra_id_82&gt;&#x27;, &#x27;&lt;extra_id_83&gt;&#x27;, &#x27;&lt;extra_id_84&gt;&#x27;, &#x27;&lt;extra_id_85&gt;&#x27;, &#x27;&lt;extra_id_86&gt;&#x27;, &#x27;&lt;extra_id_87&gt;&#x27;, &#x27;&lt;extra_id_88&gt;&#x27;, &#x27;&lt;extra_id_89&gt;&#x27;, &#x27;&lt;extra_id_90&gt;&#x27;, &#x27;&lt;extra_id_91&gt;&#x27;, &#x27;&lt;extra_id_92&gt;&#x27;, &#x27;&lt;extra_id_93&gt;&#x27;, &#x27;&lt;extra_id_94&gt;&#x27;, &#x27;&lt;extra_id_95&gt;&#x27;, &#x27;&lt;extra_id_96&gt;&#x27;, &#x27;&lt;extra_id_97&gt;&#x27;, &#x27;&lt;extra_id_98&gt;&#x27;, &#x27;&lt;extra_id_99&gt;&#x27;]}, clean_up_tokenization_spaces=True), use_caching=False),\n",
       "             param_grid={&#x27;max_samples&#x27;: [3, 5, 7]}, refit=False,\n",
       "             scoring=[&#x27;accuracy&#x27;, &#x27;neg_log_loss&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: FewShotClassifier</label><div class=\"sk-toggleable__content\"><pre>FewShotClassifier(model=&#x27;T5ForConditionalGeneration&#x27;, tokenizer=&#x27;T5TokenizerFast&#x27;, use_caching=False)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FewShotClassifier</label><div class=\"sk-toggleable__content\"><pre>FewShotClassifier(model=&#x27;T5ForConditionalGeneration&#x27;, tokenizer=&#x27;T5TokenizerFast&#x27;, use_caching=False)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=FewShotClassifier(model=T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_...\n",
       "), tokenizer=T5TokenizerFast(name_or_path='google/flan-t5-small', vocab_size=32100, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=True), use_caching=False),\n",
       "             param_grid={'max_samples': [3, 5, 7]}, refit=False,\n",
       "             scoring=['accuracy', 'neg_log_loss'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time search.fit(X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f03ff250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>param_max_samples</th>\n",
       "      <th>mean_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.93</td>\n",
       "      <td>-0.229098</td>\n",
       "      <td>3</td>\n",
       "      <td>11.638826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.92</td>\n",
       "      <td>-0.226095</td>\n",
       "      <td>5</td>\n",
       "      <td>14.855145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.92</td>\n",
       "      <td>-0.237397</td>\n",
       "      <td>7</td>\n",
       "      <td>42.713128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_accuracy  mean_test_neg_log_loss param_max_samples  \\\n",
       "0                0.93               -0.229098                 3   \n",
       "1                0.92               -0.226095                 5   \n",
       "2                0.92               -0.237397                 7   \n",
       "\n",
       "   mean_score_time  \n",
       "0        11.638826  \n",
       "1        14.855145  \n",
       "2        42.713128  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(search.cv_results_)[['mean_test_accuracy', 'mean_test_neg_log_loss', 'param_max_samples', 'mean_score_time']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d357f92c",
   "metadata": {},
   "source": [
    "**Conclusion**: There is no significant change in accuracy compared to zero-shot but a medium improvement in log loss. Having more samples doesn't help but slows down the inference time, as we can see when looking at `mean_score_time`. Overall, few-shot learning helps a bit but makes inference slower. It's up to you to decide if the trade-off is worth it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625dbfb1",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6fd974",
   "metadata": {},
   "source": [
    "Working with LLMs can be difficult because it is hard to know for certain if the prompt works well and if the LLM is capable of classifying the input. For this reason, skorch provides a few options to help identify those issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6781c236",
   "metadata": {},
   "source": [
    "### Returning unnormalized probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bd1569",
   "metadata": {},
   "source": [
    "By default, the model will normalize the probabilities to sum to 1. This is what is expected when calling `predict_proba`. However, this can hide underlying issues. The LLM can in theory predict any token from its vocabulary, there is no guarantee that it will choose one of the provided labels. skorch will force the LLM to use one of the labels, but we also track the probabilities assigned, or not assigned, to these labels.\n",
    "\n",
    "To give an example, for a given input, it's possible that the LLM predicts a probability of 10% that the label is 'negative' and 70% that it is 'positive'. By default, we normalize the probability to be 1, i.e. we return 0.125 and 0.875. The problem is that we would return the same normalized probabilities even if the model predicts 1% and 7%. But if the model predicts such low probabilities, there is probably something wrong and we would like to know about it.\n",
    "\n",
    "For this reason, we added the option to disable the normalization of probabilities. Let's check how well our zero-shot flan-t5 model is doing without normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b413434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ZeroShotClassifier('google/flan-t5-small', use_caching=False, probas_sum_to_1=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a8cbf42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ZeroShotClassifier(model_name=&#x27;google/flan-t5-small&#x27;, probas_sum_to_1=False, use_caching=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ZeroShotClassifier</label><div class=\"sk-toggleable__content\"><pre>ZeroShotClassifier(model_name=&#x27;google/flan-t5-small&#x27;, probas_sum_to_1=False, use_caching=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ZeroShotClassifier(model_name='google/flan-t5-small', probas_sum_to_1=False, use_caching=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=None, y=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22f084a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = clf.predict_proba(X[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ec3008a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55589342, 0.43614349],\n",
       "       [0.56059146, 0.43085057],\n",
       "       [0.94313842, 0.04362511]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e668cf37",
   "metadata": {},
   "source": [
    "Let's check the sum of the two classes combined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b11fb92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99203691, 0.99144202, 0.98676353])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba.sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dc1cc1",
   "metadata": {},
   "source": [
    "As you can see, the summed probabilities returned by flan-t5 are quite high. Without normalization, they still sum up to ~99%, which is very good.\n",
    "\n",
    "Now let's take a look at an LLM that doesn't work well for this task, GPT2.\n",
    "\n",
    "Note that, in contrast to flan-t5, GPT2 is a decoder-only language model, we don't need to set `use_caching=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3446c6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ZeroShotClassifier('gpt2', probas_sum_to_1=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1cd3b9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ZeroShotClassifier(model_name=&#x27;gpt2&#x27;, probas_sum_to_1=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ZeroShotClassifier</label><div class=\"sk-toggleable__content\"><pre>ZeroShotClassifier(model_name=&#x27;gpt2&#x27;, probas_sum_to_1=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ZeroShotClassifier(model_name='gpt2', probas_sum_to_1=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=None, y=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4f07575",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "y_proba = clf.predict_proba(X[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e0177a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.86091414e-13, 1.38600503e-12],\n",
       "       [2.50074673e-13, 8.08236941e-13],\n",
       "       [3.82718732e-13, 1.23716673e-12]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907cad23",
   "metadata": {},
   "source": [
    "As we can see, the probabilities are really low, but if we had normalized them, we might not have noticed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "882ec313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21787269, 0.78212731],\n",
       "       [0.23629588, 0.76370412],\n",
       "       [0.23626284, 0.76373716]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize probabilities to sum up to 1\n",
    "y_proba / y_proba.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b5842e",
   "metadata": {},
   "source": [
    "This means we should probably use a different LLM or tinker with the prompt until we get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbf72cd",
   "metadata": {},
   "source": [
    "### Specific actions when probabilities are low"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c235b6ef",
   "metadata": {},
   "source": [
    "There are more options to identify low probabilities in a way that does not require manually inspecting the probabilities. For this, we provide two arguments for `ZeroShotClassifier` and `FewShotClassifier`:\n",
    "\n",
    "The first argument is called `error_low_prob`. It should be one of the following strings: `'ignore'`, `'warn'`, `'raise'`, or `'return_none'`.\n",
    "\n",
    "By default, it is `'ignore'`, which means that nothing happens, no matter how low the predicted proabilities. By setting it to `'warn'`, there will be a warning when the total probabilities of at least one predicted sample is too low. Use this option if you want to get the result but be alerted about possible problems.\n",
    "\n",
    "By passing `error_low_prob='raise'`, an error will be raised as soon as a sample with low total probabilities is encountered. This is useful if you want inference to stop immediately, instead of waiting for all predictions to be made.\n",
    "\n",
    "Finally, you can set `error_low_prob='return_none'`. In this case, nothing changes when calling `predict_proba`. When calling `predict`, however, the probabilities for the samples will be checked and if they're too low, the prediction will be replaced by `None`. This is useful if the predictions are generally good, but some examples are, for one reason or another, hard to predict.\n",
    "\n",
    "The second parameter, which should be used in conjunction with `error_low_prob`, is called `threshold_low_prob`. This is simply a float between 0 and 1 that indicates what the probability is that should be considered \"low\". Note that this value is compared to the _sum of the probability for all labels_ of a given sample. So when setting `threshold_low_prob=0.1`, and the probability for 'negative' is 0.05, but the probability for 'positive' is 0.2, this would be fine because in total, their probabilities exceed 0.1.\n",
    "\n",
    "Let's see how this works in practice by using the option to raise an error and setting the threshold to 0.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "035392d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that since GPT2 is a decoder-only language model, we don't need to set use_caching=False\n",
    "clf = ZeroShotClassifier('gpt2', error_low_prob='raise', threshold_low_prob=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c9fa255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ZeroShotClassifier(error_low_prob=&#x27;raise&#x27;, model_name=&#x27;gpt2&#x27;, threshold_low_prob=0.5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ZeroShotClassifier</label><div class=\"sk-toggleable__content\"><pre>ZeroShotClassifier(error_low_prob=&#x27;raise&#x27;, model_name=&#x27;gpt2&#x27;, threshold_low_prob=0.5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ZeroShotClassifier(error_low_prob='raise', model_name='gpt2', threshold_low_prob=0.5)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=None, y=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3092ea4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an error: The sum of all probabilities is 0.000, which is below the minimum threshold of 0.500\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    clf.predict_proba(X[:3])\n",
    "except Exception as exc:\n",
    "    print(\"There was an error:\", exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae9eabf",
   "metadata": {},
   "source": [
    "As you can see, we indeed got an error, alerting us immediately to potential issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5899b0bc",
   "metadata": {},
   "source": [
    "## Testing MNLI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318fb816",
   "metadata": {},
   "source": [
    "There are other zero-shot classification methods out there. One such method is to use natural language inference (NLI). In a nutshell, this method works by creating the text embedding for the input and the embeddings for each label, then calculating the probability based on the similarity of the text and label embeddings.\n",
    "\n",
    "Let's compare the results to https://huggingface.co/facebook/bart-large-mnli, which is the most used zero-shot classifier on Hugging Face at the time of writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1764b077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d3bf7743",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline('zero-shot-classification', model='facebook/bart-large-mnli', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d1899abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.1 s, sys: 121 µs, total: 13.1 s\n",
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%time preds = classifier(imdb['train'][:100]['text'], ['negative', 'positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1ef6c2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = np.vstack([p['scores'] if p['labels'] == ['negative', 'positive'] else p['scores'][::-1] for p in preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "66d29e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, y_proba.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4da4ea3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3443705626436628"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y, y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e7ce7",
   "metadata": {},
   "source": [
    "**Conclusion**: This model is slower than the tested zero-shot classifier, it is less flexible (we cannot adjust prompt or other parameters), and it performs worse. For this task, it is, therefore, better to use skorch's `ZeroShotClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8196ec",
   "metadata": {},
   "source": [
    "## Testing a standard machine learning solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245748e2",
   "metadata": {},
   "source": [
    "Finally, let's compare the results to a classical supervised machine learning approach. For this, we use TFIDF to vectorize the input and a logistic regression for classification. This a standard pipeline for text classification tasks and works really well with enough data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37dbcd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f39164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef2d783",
   "metadata": {},
   "source": [
    "Let's run a grid search on a couple of hyper-parameters to ensure we pick good ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "55cfe9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'tfidf__max_features': [500, 1000], 'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f465c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(\n",
    "    tfidf, param_grid=params, cv=2, scoring=['accuracy', 'neg_log_loss'], refit=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5a4eca10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 630 ms, sys: 79 µs, total: 630 ms\n",
      "Wall time: 629 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;clf&#x27;, LogisticRegression())]),\n",
       "             param_grid={&#x27;tfidf__max_features&#x27;: [500, 1000],\n",
       "                         &#x27;tfidf__ngram_range&#x27;: [(1, 1), (1, 2), (1, 3)]},\n",
       "             refit=False, scoring=[&#x27;accuracy&#x27;, &#x27;neg_log_loss&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;clf&#x27;, LogisticRegression())]),\n",
       "             param_grid={&#x27;tfidf__max_features&#x27;: [500, 1000],\n",
       "                         &#x27;tfidf__ngram_range&#x27;: [(1, 1), (1, 2), (1, 3)]},\n",
       "             refit=False, scoring=[&#x27;accuracy&#x27;, &#x27;neg_log_loss&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                       ('clf', LogisticRegression())]),\n",
       "             param_grid={'tfidf__max_features': [500, 1000],\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
       "             refit=False, scoring=['accuracy', 'neg_log_loss'])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time search.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a8f9af",
   "metadata": {},
   "source": [
    "The table is quite big, let's look at the top 5 best log losses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "26a18072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>param_tfidf__max_features</th>\n",
       "      <th>param_tfidf__ngram_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.69</td>\n",
       "      <td>-0.662397</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.71</td>\n",
       "      <td>-0.663959</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.664004</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.664215</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.65</td>\n",
       "      <td>-0.664609</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_accuracy  mean_test_neg_log_loss param_tfidf__max_features  \\\n",
       "2                0.69               -0.662397                       500   \n",
       "5                0.71               -0.663959                      1000   \n",
       "1                0.68               -0.664004                       500   \n",
       "4                0.70               -0.664215                      1000   \n",
       "0                0.65               -0.664609                       500   \n",
       "\n",
       "  param_tfidf__ngram_range  \n",
       "2                   (1, 3)  \n",
       "5                   (1, 3)  \n",
       "1                   (1, 2)  \n",
       "4                   (1, 2)  \n",
       "0                   (1, 1)  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['mean_test_accuracy', 'mean_test_neg_log_loss', 'param_tfidf__max_features', 'param_tfidf__ngram_range']\n",
    "pd.DataFrame(search.cv_results_)[cols].sort_values('mean_test_neg_log_loss', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34859e8c",
   "metadata": {},
   "source": [
    "**Conclusion**: This classical model is much faster, even if we include the training time, because it is much smaller than a language model. However, it's scores are also much worse, which is due to the small size of the dataset. If speed is no concern, using an LLM classifier would thus be a good option for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a5092b",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d07164",
   "metadata": {},
   "source": [
    "In this notebook, we learned how to use skorch's `ZeroShotClassifier` and `FewShotClassifier` for a text classification task. Let's list a few advantages that we gained from using those classes:\n",
    "\n",
    "- On this particular dataset, zero- and few-shot learning outperformed a classical supervised machine learning approach. We also got better scores than what we got from MNLI.\n",
    "- We can use `ZeroShotClassifier` and `FewShotClassifier` as drop-in replacement for other sklearn text classification models because `fit`, `predict`, and `predict_proba` work as expected from an sklearn model.\n",
    "- It is trivial to run a grid search. This way, we can find out what model works best, what prompt is optimal, and how many few-shot samples to provide.\n",
    "- We can call `predict_proba` to get the (relative) probability the model assigns to each label, which is not something we normally get from a language model.\n",
    "- `ZeroShotClassifier` and `FewShotClassifier` also give us some nice extra features. Most notably, they force the language models to predict one of the provided labels, which is typically not a guarantee when using language models. We also get easy ways to detect issues and caching (for decoder-only models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba90aa96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9db751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f146eba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c4c6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4561e96f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d004d475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fd48b34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ZeroShotClassifier('bigscience/bloom-560m', device=device, probas_sum_to_1=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "57ff1f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.58 s, sys: 918 ms, total: 9.49 s\n",
      "Wall time: 8.76 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ZeroShotClassifier(device=&#x27;cuda:0&#x27;, model_name=&#x27;bigscience/bloom-560m&#x27;, probas_sum_to_1=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ZeroShotClassifier</label><div class=\"sk-toggleable__content\"><pre>ZeroShotClassifier(device=&#x27;cuda:0&#x27;, model_name=&#x27;bigscience/bloom-560m&#x27;, probas_sum_to_1=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ZeroShotClassifier(device='cuda:0', model_name='bigscience/bloom-560m', probas_sum_to_1=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X=None, y=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "be9b8982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.4 s, sys: 1.56 s, total: 35 s\n",
      "Wall time: 8.92 s\n"
     ]
    }
   ],
   "source": [
    "%time y_proba = clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efa8bbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (844 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.3 s, sys: 1.41 s, total: 30.7 s\n",
      "Wall time: 8.15 s\n"
     ]
    }
   ],
   "source": [
    "%time y_proba = clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629b39b3",
   "metadata": {},
   "source": [
    "The prediction speed is a bit slow, as should be expected from a language model. If runtime is a big concern, this is probably not the right approach.\n",
    "\n",
    "Now let's check how well the model does. First we check the log loss, then the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e7ba530",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2870120002577984"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af917e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_proba.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b25c91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1191c40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006928366277497844"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba.sum(1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31f0735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6634bd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ZeroShotClassifier('bigscience/bloomz-1b1', device=device, probas_sum_to_1=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d75e9358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/715 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/2.13G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/222 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.6 s, sys: 5.39 s, total: 23 s\n",
      "Wall time: 1min 31s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ZeroShotClassifier(device=&#x27;cuda:0&#x27;, model_name=&#x27;bigscience/bloomz-1b1&#x27;, probas_sum_to_1=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ZeroShotClassifier</label><div class=\"sk-toggleable__content\"><pre>ZeroShotClassifier(device=&#x27;cuda:0&#x27;, model_name=&#x27;bigscience/bloomz-1b1&#x27;, probas_sum_to_1=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ZeroShotClassifier(device='cuda:0', model_name='bigscience/bloomz-1b1', probas_sum_to_1=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X=None, y=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b80a40e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.1 s, sys: 2.37 s, total: 58.5 s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%time y_proba = clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5f57ea57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.43 s, sys: 67.9 ms, total: 1.5 s\n",
      "Wall time: 377 ms\n"
     ]
    }
   ],
   "source": [
    "%time y_proba = clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638a0bf0",
   "metadata": {},
   "source": [
    "The prediction speed is a bit slow, as should be expected from a language model. If runtime is a big concern, this is probably not the right approach.\n",
    "\n",
    "Now let's check how well the model does. First we check the log loss, then the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0b532e7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2500488762914562"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f2f38c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_proba.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8f584222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "51eda602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7575816854927688"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba.sum(1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "16b2d6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"I'm very happy with this new smartphone. The display is excellent and the battery lasts for days. My only complaint is the camera, which could be better. Overall, I can highly recommend this product.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "209cdce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05547452, 0.94452548]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp = clf.predict_proba([s])\n",
    "yp / yp.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ad66bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9fd7c7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.llm import DEFAULT_PROMPT_ZERO_SHOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7ce91b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_prompt = \"\"\"Your job is to analyze the sentiment of customer reviews.\n",
    "\n",
    "The available sentiments are: {labels}\n",
    "\n",
    "The customer review is:\n",
    "\n",
    "```\n",
    "{text}\n",
    "```\n",
    "\n",
    "Your response:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "78b02250",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ZeroShotClassifier('bigscience/bloomz-1b1', device='cpu', prompt=my_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d2b7ec5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.7 s, sys: 1.75 s, total: 15.5 s\n",
      "Wall time: 14.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ZeroShotClassifier(model_name=&#x27;bigscience/bloomz-1b1&#x27;, prompt=&#x27;Your job is to analyze the sentiment of customer reviews.\\n\\nThe available sentiments are: {labels}\\n\\nThe customer review is:\\n\\n```\\n{text}\\n```\\n\\nYour response:&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ZeroShotClassifier</label><div class=\"sk-toggleable__content\"><pre>ZeroShotClassifier(model_name=&#x27;bigscience/bloomz-1b1&#x27;, prompt=&#x27;Your job is to analyze the sentiment of customer reviews.\\n\\nThe available sentiments are: {labels}\\n\\nThe customer review is:\\n\\n```\\n{text}\\n```\\n\\nYour response:&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ZeroShotClassifier(model_name='bigscience/bloomz-1b1', prompt='Your job is to analyze the sentiment of customer reviews.\\n\\nThe available sentiments are: {labels}\\n\\nThe customer review is:\\n\\n```\\n{text}\\n```\\n\\nYour response:')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X=None, y=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "64d0ac1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive'], dtype='<U8')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b8a403ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04346025, 0.95653975]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba([s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aad2364",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
